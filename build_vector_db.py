import sys
import os
# Th√™m th∆∞ m·ª•c hi·ªán t·∫°i v√†o path ƒë·ªÉ import ƒë∆∞·ª£c module app
sys.path.append(os.getcwd())

from sqlalchemy.orm import Session, joinedload
from app.db.session import SessionLocal
from app.models.database import Medicines 
from app.models.database import Brand     

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

# --- C·∫§U H√åNH ---
VECTOR_DB_PATH = "faiss_index_store"
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

def fetch_data_from_db():
    """
    Thay v√¨ g·ªçi API, ta m·ªü k·∫øt n·ªëi DB tr·ª±c ti·∫øp
    """
    db: Session = SessionLocal()
    try:
        # Query tr·ª±c ti·∫øp qua SQLAlchemy v·ªõi eager loading cho brand relationship
        # ƒêi·ªÅu n√†y s·∫Ω load brand c√πng l√∫c v·ªõi medicines, tr√°nh DetachedInstanceError
        medicines = db.query(Medicines).options(joinedload(Medicines.brand)).all() 
        
        print(f"ƒê√£ query ƒë∆∞·ª£c {len(medicines)} thu·ªëc t·ª´ MySQL.")
        return medicines
    except Exception as e:
        print(f"‚ùå L·ªói DB: {e}")
        return []
    finally:
        db.close()

def prepare_documents(medicines_list):
    documents = []
    for item in medicines_list:
        # item b√¢y gi·ªù l√† Object SQLAlchemy, truy c·∫≠p b·∫±ng d·∫•u ch·∫•m (.)
        
        # X·ª≠ l√Ω quan h·ªá (n·∫øu Brand l√† relationship)
        # Brand ƒë√£ ƒë∆∞·ª£c eager load n√™n kh√¥ng b·ªã DetachedInstanceError
        brand_name = item.brand.name if item.brand else "Kh√¥ng r√µ"
        
        # L·∫•y ·∫£nh ƒë·∫ßu ti√™n (gi·∫£ s·ª≠ images l√† list JSON ho·∫∑c string)
        # T√πy v√†o c√°ch b·∫°n l∆∞u trong DB m√† x·ª≠ l√Ω
        image_url = ""
        if hasattr(item, 'images') and item.images:
             # Gi·∫£ s·ª≠ logic l·∫•y ·∫£nh ·ªü ƒë√¢y
             image_url = str(item.images[0]) if isinstance(item.images, list) else str(item.images)

        # T·∫°o n·ªôi dung vector
        content_text = (
            f"T√™n thu·ªëc: {item.name}. "
            f"T√™n g·ªëc: {item.generic_name}. "
            f"Th∆∞∆°ng hi·ªáu: {brand_name}. "
            f"C√¥ng d·ª•ng: {item.description}. "
            f"C√°ch d√πng: {item.dosage}. "
            f"T√°c d·ª•ng ph·ª•: {item.side_effects}."
        )
        
        metadata = {
            "medicine_id": item.id, # ID t·ª´ DB
            "name": item.name,
            "price": float(item.price) if item.price else 0,
            "image_url": image_url,
            "source": "Direct_MySQL"
        }
        
        doc = Document(page_content=content_text, metadata=metadata)
        documents.append(doc)
    
    return documents

def build_vector_db():
    print("üöÄ B·∫Øt ƒë·∫ßu t·∫°o Vector DB t·ª´ MySQL tr·ª±c ti·∫øp...")

    # 1. L·∫•y d·ªØ li·ªáu t·ª´ DB
    raw_data = fetch_data_from_db()
    if not raw_data: return

    # 2. Convert sang Document
    documents = prepare_documents(raw_data)

    # 3. Split text
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    splitted_docs = text_splitter.split_documents(documents)

    # 4. Embedding & Save
    print(f"üß† ƒêang t·∫£i model embedding & t·∫°o Index...")
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
    db = FAISS.from_documents(splitted_docs, embeddings)
    
    db.save_local(VECTOR_DB_PATH)
    print(f"‚úÖ Ho√†n t·∫•t! Vector DB ƒë√£ l∆∞u t·∫°i '{VECTOR_DB_PATH}'")

if __name__ == "__main__":
    build_vector_db()